Programming Paradigms: Lecture notes

How to read this document: 
- Simple: plain text, header level is indicated by number of *
- Better: Use emacs [[http://orgmode.org/][org mode]]. 
  + Use <TAB> to expand/collapse nodes. 
  + C-c C-e b to do HTML rendering and open in your browser
  + Check out the [[http://orgmode.org/orgcard.txt][reference card]].
- Sometimes the difficulty of a section is indicated by a number of stars:
  + (⋆) material required to pass the course
  + (⋆⋆) material for grade 4
  + (⋆⋆⋆) only for grade 5 
  + (✪) not formally part of the course material

* Introduction + Programming Paradigms in General

- Programming paradigms
 (pronounciation: ˈpærədaɪm (us?)) 
- DAT121 / DIT...

** The teaching team
*** JP Bernardy
Course responsible & Lecturer

Contact:
- Room: 6126
- E-mail: bernardy@chalmers.se

CV:
- 1996-2000: Master in CS (Free University of Brussels)
- 2000-2007: Software engineer at various places
- 2007-2011: PhD (Chalmers)

*** Ramona Enache
Assistant
*** Michal Pałka
Assistant

** Schedule & Organisation
*** Formal requirements:
- Pass the exam
- Participate in the exercises correction sessions (bonus points)
- Do the exercises
- Attend the lectures
- Prepare lectures by reading lecture notes
*** Lectures
Please interrupt me during lectures!
*** TODO Exercises
Time:
Your group:
*** TODO Office hours
JP:
Ramona:
Michal:
*** Course evaluation

See: https://student.portal.chalmers.se/en/studies/pages/courseevaluation.aspx

2-6 Volunteers needed
- Discuss the course with other students, represent their views to the teachers.
- Cremona voucher for 200SEK
- Volunteer _today_ !

*** Reading material
- Scattered across this document
- Single most relevant textbook: probably

  "Programming Languages -- Application and Interpretation", Shriram Krishnamurthi.
  http://www.plai.org/
  http://www.cs.brown.edu/~sk/Publications/Books/ProgLangs/2007-04-26/

 ... but uses different structure, and scheme (LISP) syntax.

**** Other relevant books

- "Essentials of Programming Languages", Friedman, Wand and Haynes (http://www.eopl3.com/)
- "Concepts, Techniques, and Models of Computer Programming", Van Roy (http://www.info.ucl.ac.be/~pvr/book.html)
- ...

** What is a "programming paradigm"?

*** Definition

http://www.merriam-webster.com/dictionary/paradigm

"A philosophical and theoretical framework of a scientific school or
discipline within which theories, laws, and generalizations and the
experiments performed in support of them are formulated; broadly: a
philosophical or theoretical framework of any kind"

see also: http://en.wikipedia.org/wiki/Programming_paradigm

*** Paradigms as "ways of organising thought"

:             Programming paradigm 
:                        = 
: The basic structuration of thought underlying the programming activity.

eg. when you think of a programming problem, what are you thinking of?

- the sequence of actions to perform (first download the file, then
  display it)
- how to divide the problem-space into sub-tasks (to compute the
  spanning tree, i can divide the graph arbitrarily in two, and then
  ...)
- what are the agents involved (sensors, a simulator, a renderer, ...)
- what data do we need to handle? do we need intermediate
  representations? what are the relations between the different forms?

Note that the same way of thinking is not adapted to all problems.

*** To each paradigm corresponds a "mental model of the computer"

How do you think of your computer?

- Memory + instructions (von Neumann model)
- Rewriting engine
- Mathematical function
- ...
  
*** Paradigms and Languages
**** (Do not reveal:) Discussion: What languages do you know? 

Regexp / Excell formulas / sql queries / Haskell / C / Asm / ...

 ⟶ clouds / recognise paradigms / discussions

- Paradigms build on top of features
- Languages implement features

http://www.info.ucl.ac.be/~pvr/paradigmsDIAGRAMeng108.pdf

**** PL Features
- Structured data / Records
- Naming and abstraction (2nd order, etc).
- Memory (cell) / State
- Processes
- Communication channels
- Recursion
- Search

*** Notion of paradigm shift
After writing many programs, you may notice patterns emerging. These
patterns may become codified, either informally (see the book of the
Gang of Four) or formally within the language (cf. Haskell Monads).

Eventually, all programming may revolve around a number of patterns;
the old ways are abandonned.  This is the paradigm shift: a new way of
thinking appears. Eventually, a new programming language may be
developed to support the "patterns" directly.

#+begin_src dot :file shift.png :cmdline -Kdot -Tpng
digraph G {
   "Programming habits" -> "(Design) patterns" -> "New Paradigm"
}
#+end_src

#+results:
[[file:shift.png]]

*** The importance of knowing multiple paradigms
**** Ability to think "big thoughts"
- Anecdote: MULTICS
- "Language as thought shaper", from http://soft.vub.ac.be/~tvcutsem/whypls.html

  To quote Alan Perlis: "a language that doesn't affect the way you
  think about programming, is not worth knowing."
  
  The goal of a thought shaper language is to change the way a
  programmer thinks about structuring his or her program. The basic
  building blocks provided by a programming language, as well as the
  ways in which they can (or cannot) be combined, will tend to lead
  programmers down a "path of least resistance", for some unit of
  resistance. For example, an imperative programming style is definitely
  the path of least resistance in C. It's possible to write functional C
  programs, but as C does not make it the path of least resistance, most
  C programs will not be functional.

  Functional programming languages, by the way, are a good example of
  thought shaper languages. By taking away assignment from the
  programmer's basic toolbox, the language really forces programmers
  coming from an imperative language to change their coding habits. I'm
  not just thinking of purely functional languages like
  Haskell. Languages like ML and Clojure make functional programming the
  path of least resistance, yet they don't entirely abolish
  side-effects. Instead, by merely de-emphasizing them, a program
  written in these languages can be characterized as a sea of
  immutability with islands of mutability, as opposed to a sea of
  mutability with islands of immutability. This subtle shift often makes
  it vastly easier to reason about the program.

  Erlang's concurrency model based on isolated processes communicating
  by messages is another example of a language design that leads to
  radically different program structure, when compared to mainstream
  multithreading models. Dijkstra's "GOTO considered harmful" and
  Hoare's Communicating Sequential Processes are pioneering examples of
  the use of language design to reshape our thoughts on programming. In
  a more recent effort, Fortress wants to steer us towards writing
  parallel(izable) programs by default.

  Expanding the analogy with natural languages, languages as thought
  shapers are not about changing the vocabulary or the grammar, but
  primarily about changing the concepts that we talk about. Erlang
  inherits most of its syntax from Prolog, but Erlang's concepts
  (processes, messages) are vastly different from Prolog's (unification,
  facts and rules, backtracking). As a programing language researcher, I
  really am convinced that language shapes thought.

**** Altenative paradigms in the industry:
- "Excell is the most used programming language"
- SQL is mostly functional (relational)
- F# officially supported by MicroSoft
- Exponential growth of Erlang / Haskell

**** Fun reading on the importance of using the right language:
http://tauday.com/

** Outline of the course
*** Brief exposition of each paradigm

Can I teach you so 5 differrent ways of thinking in 7 weeks? 
Each of these would require major rewiring of your brain. Difficult!
But fear not... Other courses are available:

- Functional ("introduction to functional programming" TDA555)
- Imperative ("machine-oriented programming" EDA480)
- Concurrent ("concurrent programming" TDA381)
- Object oriented ("Object oriented programming" DAT042)
- Logic (?)
*** (Some) Transformations between paradigms
*This is the focus of the course.*
*** Learning outcomes
**** Awareness of multiple paradigms
First questions of the design phase: "How should I think about this
problem? (Do I know a paradigm suitable to express the solution?)"
**** Recognise "encoded" thoughts:
***** what is the natural paradigm
***** decode them
**** Encode thoughts expressed in a paradigm in another one

**** The exam questions will be similar to exercises
Note in particular that exercises are integral part of the course material.

* Prelude: A crash course on types

Types are essential to get a quick overview of what a program is
"about". Very useful when facing abstract programs! Hence, they are
important in this course since some paradigms have high "expression
power".

Here I use the colon ':' to denote the typing relation. 

*** Some examples:

1. 0 : Int
2. 1 : Int
3. 'c' : Char
4. "hello" : String
5. (1/2) : Rational

*** Paramerisation of programs / Abstraction / Function types

Take a simple value like this:

:    greetMe = "Hello, Jean-Philippe! How are you today?" 
:    greetMe : String


That's very useless as a program! We want to be able to greet more
than one person, and parametrize (or abstract) over the name of the
person greeted:


:    greet(name) = "Hello, " ++ name ++ " How are you today?" 


The above makes sense only when 'name' is a string, and in that case
greet(name) is a string. 

:    name : String    ⊢    "Hello, " ++ name ++ " How are you today?" : String

We can then deduce that "greet" is a function taking a string into a
string, written formally as follows:

:   greet : String → String

*** Trivia: types of the following
1. factorial : ?  
2. π : ?  
3. sin : ?
4. × : ?   (multiplicaton)
5. derivative : ? (or ∫ : ?) (review this question after FP paradigm...)
   - hint: remember that derivative maps sin to cos.
* Imperative programming
** Paradigm

1. do this
2. then do that
3. then do some otherthing 
4. if not done, then repeat 2. and 3. 

(cf. cookbook...
   ... for beginner cooks :)

*** Computing model
"von neumann" model of the computer:

- Memory cells
- Program (assignments, arithmetic, logic, (conditional) jumps)

** Example

*** Gotos

#+begin_example
   -- Assume A : list of sortable items

   begin:
        swapped = false
        i := 1;
   loop:
        if A[i-1] <= A[i] goto no_swap
        swap( A[i-1], A[i] )
        swapped = true
   no_swap:
        i := i+1
        if i < n then goto loop
        if swapped goto begin
#+end_example

*** Loops & Ifs

#+begin_example
   -- Assume A : list of sortable items

      while swapped
        swapped = false
        for each i in 1 to length(A) - 1 inclusive do:
          if A[i-1] > A[i] then
            swap( A[i-1], A[i] )
            swapped = true
          end if
        end for
#+end_example

*** Wrapping in a procedure for good measure
#+begin_example
    procedure bubbleSort( A : list of sortable items )
      do
        swapped = false
        for each i in 1 to length(A) - 1 inclusive do:
          if A[i-1] > A[i] then
            swap( A[i-1], A[i] )
            swapped = true
          end if
        end for
      while swapped
    end procedure
#+end_example

** Discussion: When are gotos appropriate?
extra reading: "goto statement considered harmful", E. G. Dijkstra
http://portal.acm.org/citation.cfm?id=362947

** Transformation: Loops ⟶ Gotos

*** Source: 
#+begin_example
while cond do
  body
#+end_example

*** Target
#+begin_example
test:
  p := cond
  if p goto done
  body
  goto test
done:
#+end_example

*** Exercise: translate the following

do
   body
until cond

** Transformation: If then else ⟶ Gotos
*** Source
if cond then
  part1
else
  part2

*** Target
  p := not(cond)
  if p then goto label2
  part1
  goto done
label2:
  part2
done:

*** Exercise: switch/case

** Reverse transformation? (Gotos ⟶ Loops)

No general form! (You must be creative)

** Passing by reference 
*** Reminder: References (aka. pointers)
**** Addresses
Assume:

#+begin_example
 x : Integer
#+end_example

Then

#+begin_example
 addressOf(x) : PointerTo Integer
#+end_example
   ≃ where in the memory is the variable x

hence:
: addressOf : Integer → PointerTo Integer

**** "De-reference"

Assuming
: p : PointerTo Integer
Then
: variableAt(p) : Integer

Hence:
: variableAt : PointerTo Integer → Integer 

**** Trivia: whats the meaning of addressOf(addressOf(x))?
 ⟶ none! because addressOf(x) is just a value, there is no location for it in the memory.
**** Exercise (⋆): re-write the above in C syntax
*** Example
**** Source:

(Supposing the language supports passing arguments by reference:)

increment(by ref. x : Int)
  x := x + 1
...

increment(y)

**** Target

(Assuming the language supports pointers:)

increment(x : PointerTo Int)
  variableAt(x) := variableAt(x) + 1

...

increment(addressOf(y))
*** Exercise (⋆): bubbleSort
*** Question: Why is passing by reference useful?
- "expressive power" : you can factor out parts of the computation that update any (sub-part of) the state
- save time : no need to copy around things

*** Exercise: Does Java use call by reference? 
  Show example(s) that says yes/no
  
** Transformation: inlining procedures
*** Source
procedure g(x,y)
  x := x + y

procedure f(x,y)
  g(x,y)
  x := x + 1
  g(y,x)

f(a,b)

*** Intermediate

procedure f(x,y)
  x := x + y
  x := x + 1
  y := y + x


f(a,b)

*** Final

a := a + b
a := a + 1
b := b + x

*** Question: What happens when the original program is recursive?
** Transformation: Procedures ⟶ Gotos & Variables
Source:
#+begin_example
function sqrt(x : Float) : Float
  result := x / 2 
  while distance (result * result, x) > ε
    -- Newton approx to refine the result
    ...
  return result;

-- the calls:
sqrt(12345)
...
...
sqrt(6789);
#+end_example

Target:
#+begin_example
sqrt:
-- argument in global variable 'sqrtArgument'
sqrtResult := sqrtArgument / 2;
-- And then newton algorithm 
...
...
-- at this point, sqrtResult contains the result.
goto sqrtCaller;

sqrtArgument := 12345;
sqrtCaller := out1;
goto sqrt;
out1:
...
...
sqrtArgument := 6789;
sqrtCaller := out2;
goto sqrt;
out2:
#+end_example

*** Trivia: What happens when the original program is recursive?

- Loop (dynamic)
- variables: a mess...
** Transformation: Explicit stack
*** 1st example: factorial.
Translation of a recursive call:
 - push local variables on a stack
 - set caller
 - goto
 - pop local variables

-----------------------------------
function fact (n:Int)
  if n = 0 then
    return 1
  else
    return n * fact(n-1)
-----------------------------------

Straightforward application of rules:

---------------------------------------
-- Call to 'fact'
caller := out;
n := 12;
goto fact;
out:

...
...

-- Definition of 'fact':
fact:
if n = 0 then
  result := 1;
  goto caller;
else 
  push(n,caller);         -- save locals         \
  caller := continue;     -- remember caller      |
  n := n-1;               -- set arguments        |    This is the translation
  goto fact;              -- jump                 |        of the call  'fact(n-1)'
continue:                                         |
  pop(n,caller);          -- restore locals       /
  result := n * result;   -- result (on the rhs of :=) is the result of the recursive call.
  goto caller;            
------------------------------------------------

*** 2nd example: factorial (alternative algorithm)
**** Source
--------------------------------
function fact (n:Int,acc:Int)
  if n = 0 then
    return acc
  else
    return fact(n-1,n * acc)
--------------------------------

**** Question: explain the algorithm.

**** Target (by straightforward application of rules)
--------------------------------
fact: -- n,acc,caller are defined here.
if n = 0 then
  result := acc;
  goto caller;
else
  push (n,acc,caller)
  acc := acc * n;
  n := n-1;
  caller := continue;
  goto fact;  
  continue:
  pop (n,acc,caller)
  result := result; -- just forward the result of the recursive call.
  goto caller;
--------------------------------

**** Improvement:
But:
 - The local variables are saved for nothing: they are not used after they are popped!
 - The result := result statement is useless.

Hence we obtain:


--------------------------------
fact: -- n,acc,caller are defined here.
if n = 0 then
  result := acc;
  goto caller;
else
  push (caller)
  acc := acc * n;
  n := n-1;
  caller := continue;
  goto fact;  
  continue:
  pop (caller)
  goto caller;
--------------------------------

What is the effect of the following?

  push (caller)
  caller := continue
  goto fact

It fact, it is the same as 

  goto fact

Indeed, after returning to "continue", the caller will just be popped
from the stack; and we'll jump to it.  This would also be done by the
normal "goto caller" return statement if we had not overwritten the
caller with continue.


Hence, the stack can be removed altogether! This is called /tail-call optimisation/. Why?


We get:
-----------------
acc := 1;
caller := out;
goto fact
out:

fact:
if n = 0 then
  result := acc;
  goto caller;
else
  acc := n * acc; -- note the order of assignments
  n := n-1;
  goto fact:
-----------------

**** Final version
Finally we can reconstruct a loop:


-------------------------
acc := 1;
while n /= 0 do
  acc := n * acc;
  n := n-1;
result := acc;
-------------------------

** Exercise
- Derecursify tree traversal (⋆⋆)
- Do you really need a stack? (⋆⋆⋆) (hint: you can update the tree as you go)
** Exercise
- Derecursify ackerman function.
* Interlude: Garbage Collection
aka. Automatic memory management
The memory is freed automatically for you! (Magic!?)

- Allows for much easier OOP
- Practically impossible to do FP/Logic without it
* Object-oriented programming
** Coupling data and related code
*** Toy example: Date

class Date

  field
    year : Integer
    month : Integer
    day : Integer


  method ShiftByDays(days : Integer);

  constructor ymd(y,m,d : Integer)
  constructor today -- -- query OS for current date


-- Example use:
appointment = today;
appointment.shiftByDays(7);

**** Note: Objects are, almost always, passed by reference.

**** Tranlated into plain records + procedures

record Date
  Year : Integer
  Month : Integer
  Day : Integer
  
function today : Date;

procedure ShiftByDays(this : Date by reference; days : Integer);
-- Why is "by reference" important?

-- Example use:
appointment = today;
shiftByDays(appointment,7);

** Encapsulation 

mechanisms to make the fields private

*** Paradigm Shift: Abstract Data Type (ADT) 
 - Example: "stack", "priority queue", ... from your data structures course
 - Every data type comes with a specification
 - ... maybe in the form of _unit tests_
 - Notion of data-invariant
 - Advantage: it's easy to change representation of data

 - Note: not every piece of data fits the ADT model. 
   Example: "Person" record.
 - Dogma: never any direct field access (cf. "set" and "get")

** Inheritance
*** Toy example:

class Animal
  method Pet
     print "Undefined"

class Dog inherits Animal
  method Pet
     print "Shake tail"

class Cat inherits Animal 
  method Pet
     print "Mew"


procedure Test(c : Animal)
  c.Feed

Test(new Dog);
Test(new Cat);

*** Transformation: embed method pointers

The above example gets translated as follows:

record Animal
  field
    Pet : function;


record Dog 
  field
    Pet : function;

procedure petDog(this : Dog);
  print "Shake tail"  -- (1)


function createDog : Dog
  return new Dog(pet = petDog);  
    

record Cat
  field 
     Pet : function;

procedure petCat(this : Cat);
  print "Shake tail"


function createCat : Cat
  return new Cat(pet = petCat);  


procedure Test(c : Animal by reference)
  c.Pet; -- (1)


Test(cast<Animal> createDog); -- (2)
Test(cast<Animal> createCat); -- (2)

**** Question: what happens on line (1)

- 'c.Pet' is a function pointer;
- the function stored in that variable is called.
- if c.Pet has been correctly set, either dog/cat case will be called.

**** Question: why are the casts (2) valid?
The layout of the parent class is exactly the same as that of the subclass.
(In general, there can be more fields/methods in the subclass, found _after_ the fields of the top class)
 
**** Liskov substitution principle and Polymorphism

if class B inherits class A, then, for any x,

   x : B  ⇒  x : A

This means that 

1. 'x' has multiple types 

2. Whenever a function 'f' for type 'A', one can pass a value of type
   'B'. By deriving from 'A', a lot of code is automatically ready to
   work with 'B'.  (Inheriting from 'A' make the function 'f' more
   useful.)

This is one instance of an important phenomenon: /polymorphism/. The
kind of polymorphism linked with inheritance is /inclusion
polymorphism/. Recall the definition of set-inclusion:


         B ⊆ A     iff     x ∈ B  ⇒  x ∈ A


***** Read (✪) more about [[http://en.wikipedia.org/wiki/Polymorphism_(computer_science)][polymorphism]].

 (http://en.wikipedia.org/wiki/Liskov_substitution_principle is badly written)

*** Exercises 
Apply the transformation on each of the following examples:

- call the function 'Vocalise' by default in the 'Pet' method
- add a StrayCat subclass which: 
  + scratches instead of meowing;
  + counts of the number of wounds inflicted.

*** What happens when functions have arguments?
In many languages, the type of the arguments of derived functions must
be the SAME as that of the overridden function.
**** Contra-variance (✪)
A perhaps natural expectation is that you could make the arguments
change as the type of the object. Ex.:

class Additive 
  method Add(Additive)

class Integer
  method Add(Integer)

... but in fact this violates the substitution principle!

Exercise: use the above two classes in a way that shows violation of
substitution.

Read: http://en.wikipedia.org/wiki/Covariance_and_contravariance_(computer_science)

*** Extension (✪): function tables

- Is the 'pet' function pointer ever modified?
- How can we save space if there are many methods per class? 

⟶ One more indirection!
**** Example
record AnimalMethods
  Pet : function
  Vocalise : function

record DogMethods
  Pet : function
  Vocalise : function
  
dogMethods = {Pet := petDog, ...}



*** Paradigm Shift

  - Multiple "cases" can be implemented by inheriting a common class
  - Dogma: no "if".
  - Specific behaviour is implemented in derived methods
  
  - Open question: multiple dispatch!

** Reading/Exercise: Javascript prototypes
http://en.wikipedia.org/wiki/ECMAScript_syntax#Objects

** Multiple-inheritance & interfaces
*** Motivation
class Computer
class Phone
class SmartPhone inherits Computer, Phone


class Person
class Student
class GradStud inherits Person, Student

1. Better reuse of code (possibly the derived class can use code from
   both its parents)
2. More polymorphism!

*** Diamond problem

On a conceptual level:

       Person (fields: Name, BirthDate, ...)
       /    \     
      /      \
  Student  Teacher
      \      /
       \    /
      Grad Student

Does a grad student have two names? ... no
BUT some other fields might need to be duplicated, if they have a
function specific to (Student, or Teacher class). (eg. A grad student
has a Boss as a teacher and another boss as a Student)

⟶ Big headache

On an implementation level:


class Person
  Name
  BirthDate


class Student inherits Person
  CourseGrade
  ...

class Teacher inherits Person
  numberOfStudents 
  ...

class GradStud inherits Student, Teacher
  

What is the record corresponding to GradStud?
If we copy all the fields, we get:


Name
BirthDate
CourseGrade
Name
BirthDate
numberOfStudents


The record can be casted to Student (as normal, the 3 last fields will
never be accessed by methods in the Student class) or Teacher (by
adding 3 to the pointer).

But what if a method in the class Student updates the BirthDate? Then
there is a problem: the gradstudent will end up with 2 different
names!

*** Interfaces

As it is often the case, the issue appears only if the shared class
has mutable fields. An important case of immutable fields are methods
(their code is fixed once an for all for a class). Hence the notion of
/Interface/: a class without fields. In Java, there is special support
for interfaces, and one can inherit many of them.

Interfaces:
 - polymorphism ✓
 - code-reuse   × 

**** Exercise (⋆⋆)
Modify the translation above to support interfaces

**** Exercise (✪)
Translation of interfaces via method tables.

** Forward reference: ``objects are poor man's [[closures]]''
 Note the similarity between objects and closures: they are both
 encoded as state/environment + fct. pointer.
** TODO Traits & Objects as fixpoints (✪)
* Functional programming
** Reading (as necessary to understand Haskell syntax): "Learn you a Haskell, for great good!"
http://learnyouahaskell.com/

** A bit of syntax

*** Function definitions

Similar to mathematical notation:

minimum (x,y) = if x < y 
                  then x
                  else y


*** (λ) abstractions / local functions

In the literature:

minimum = λ(x,y). if x < y 
                      then x
                      else y


In Haskell:

minimum = \(x,y) -> if x < y 
                      then x
                      else y


*** Application BINDS TO THE LEFT.

No need for parentheses:

f x   ==  f(x)

Left leaning:

f x y == (f x) y  ==  (f(x))(y)

** Algebraic Types
   
If A and B are data types, then...

what is  A + B ?

         similar to union in C (what is the difference?)

         A × B ?

         similar to records in C (difference?)


Let's count the number of inhabitants of the type:

    #(A + B) = #A + #B
    #(A × B) = #A × #B

To "bootstrap" we also need types 0 (empty type, unit of +) and 1 (singleton, unit of ×)

*** Trivia (✪): what is A → B, algebraically ?
*** Examples

Bool = 1 + 1

Giving a name to the cases:

Bool = (True : 1) + (False : 1)

In Haskell syntax:

data Bool = True | False

Lists can be defined as follows, using _recursion_:
List a = (Nil : a) + (Cons : a × List a)


Haskell syntax:

data List a = Nil a | Cons a (List a)


Lists as a

*** Exercise
 - define an algebraic type for binary trees
 - define an algebraic type for arithmetic expressions
 - simple interpreter
*** Transformation: Algebraic data type ⟶ inheritance

** Higher-order functions
*** Example: fold (sometimes called reduce)

-- sum the elements in a list
sum Nil          = 0
sum (Cons x xs)  = x + sum xs


-- multiply the elements in a list
product Nil         = 1
product (Cons x xs) = 1 * product xs


Same pattern ⟶ Abstract out the difference ! (Parameterize)


foldr :: (a -> b -> b) -> b -> [a] -> b
foldr = ?


sum xs = foldr (\x y -> x + y) 0 xs


'foldr' is a function taking another function in parameter: a higher order function.

*** TODO Example: map

multiplyBy n Nil = Nil
multiplyBy n (Cons x xs) = Cons (n*x) (multiplyBy n xs)

map :: (a -> b) -> List a -> List b



*** Exercise: write a function that does the dot-product of a vector; then Abstract.

What do you get?    

*** Reading: 
"Can Programming Be Liberated From the von Neumann Style?", John
Backus, 1977 Turing Award Lecture
http://www.thocp.net/biographies/papers/backus_turingaward_lecture.pdf
(recommended to read up to p. 620).

** Removing Higher-Order functions
*** Transformation: Inlining higher-order functions

Example/Exercise: from "filter/map" to for loop...



inverse of abstraction

map : (a -> b) -> List a -> List b
map f xs = case xs of 
   [] ->  []
   (x:xs) -> f x : map f xs


multiply n xs = map (\x -> x * n) xs


replace 'f' by its value in the code of 'map':


multiply n xs = case xs of
    [] ->  []
    (x:xs) -> (\x -> x * n) x : recursiveCall f xs


β-reduce:

multiply n xs = case xs of
    [] ->  []
    (x:xs) -> x * n : recursiveCall f xs


Downside: 
- explosion of the code size
- maybe impossible! (eg. the code of map is not available -- map itself is abstract)

*** Transformation: Defunctionalisation (explicit closures)
# <<closures>>
**** Example

map : (a -> b) -> List a -> List b
map f [] = []
map f (x:xs) = f x : map f xs


multiplyBy n = map (\x -> x * n) 


map : Closure -> List a -> List b
map f [] = []
map f (x:xs) = apply f x : map f xs


multiplyBy n = map (Multiply n)

apply (Multiply n) x = x * n

data Closure = Multiply Int | ...

**** Read: 
http://en.wikipedia.org/wiki/Closure_(computer_science)


**** Exercise: Implement the above example C. 
Hint: Instead of a 'tag', use a function pointer.

....

Note the similarity with [[objects]]!

**** Exercise: Implement the above example Java
Hint: Instead of a tag, make a derived class ('apply' is a method)

** Transformation: Explicit State

- Can we represent imperative program without using side effects?
- Idea: pass around the "state of the world" explicitly
- Functions are transformed as follows:

  print : () -- in an imperative language, the state is implicit

  print : State -> State × () -- after making the state explicit



Assuming the "state of the world" is only the contents of the output
file, then print does what?


*** Exercise: implement "safePrint" functionally...

procedure safePrint(line) : ErrorCode
  if outOfInk then
    return -1
  else
    print(line)

... given the imperative function

outOfInk : Bool

 1. What is the type of outOfInk in the functional representation ?
 2. What is the translation ?

*** Imperative syntax in Haskell

-- "IP a": type of imperative programs returning a value of type a.
: type IP a = State -> State × a

Generic way to sequence two "IP a":

andThen : IP a -> IP b -> IP b
f `andThen` g = \s0 -> let (s1,a) = f s0
                           (s2,b) = g s1
                       in  (s2,b)


But what if the 2nd program uses the returned value of the 1st?
Then (in general) the 2nd program must depend on 'a':

andThen : IP a -> (a -> IP b) -> IP b
f `andThen` g = \s0 -> let (s1,a) = f s0
                           (s2,b) = g a s1
                       in  (s2,b)

If you _can_ define a function with the above type, then Haskell gives
you special syntax for imperative programming. If you give:

instance Monad IP where
  (>>=) = andThen
  return x = -- when x does not depend on the state:


Then the following is valid:

#+begin_src haskell
  safePrint line = do
    condition <- outOfInk  
    if outOfInk 
      then return -1
      else do print line
              return 0
#+end_src
            
In fact, the meaning of "imperative" is given by that function -- andThen in our case:

#+begin_src haskell 
safePrint line = 
  outOfInk `andThen` \condition ->
  if outOfInk 
    then return -1
    else print line `andThen` \() ->
         return 0
#+end_src

** Transformation: Currification

f : (A × B) → C
f = ...

g : A → (B → C)
g a = \b -> f (a,b)

h : (A × B) → C
h (a,b) = g a b

Remark: f ≡ h

*** Note: try to read A → B as B^A
... then, what is currification?
**** Extra: can you implement other algebraic laws?

** TODO Paradigm shift: HOT!
Higher-Order and Typed
- Much more opportunites for abstraction 
  + Good for reuse!
- Types capture a coarse-grained meaning of each function
  + One does not get lost in keeping track of details (so easily)
- Further reading (⋆) 
   + Haskell vs. Ada vs. C++ vs. Awk vs. ... ─ An Experiment in Software Prototyping Productivity
   + especially, sec. 6.1, 7, 8
   + http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.1208&rep=rep1&type=pdf

** Purity and its Consequences

Did you know that side effects...
 - are a common source of bugs?
 - make testing difficult?
 - make reasoning difficult?
 - make parallelizing diffcult?
 - cause cancer?

*** Referential transparency

    Mathematical function (sin)

     vs. 

    Function in (say) Java (getChar)

*** Testing is MUCH easier

       (no guesswork to know what a function depends on)

*** More optimisations possible (which ones?)
*** Easier concurrency (cf. Erlang)

    x = 0
    x = x+1 |in parallel with| x = x + 1
  
    Value of x ?     

*** Sharing is ALWAYS safe! (see in a moment)

*** Possible to use laziness  (see in a moment)

** Copying and sharing

Example: tree update

** Laziness

*** Question: How much memory is used by map?

- l : List Int
- length l = n
- How much is consumed by:

    map (+1) l

**** Same question, but assume that only the 1st element of the new list is used in the rest of the program

**** Same question, but assume 'l' is no longer used in the rest of the program.

⟶ Some say: "in Haskell, lists are a _control structure_".

** Paradigm shift: composition of transformations

- When writing a search function, the programmer can ALWAYS (and ONLY)
  return a list of ALL possible results.

- Programs can be understood as 

- Dogma: no side effect (eg. no global state)

*** Trivia: what is the most used lazy language?
- Probably SQL!
- But remember also unix-shell pipes:
  
   cat /etc/password | grep 'group=admin' | head 

*** Read: _Why functional programming matters_, J. Hughes.

** Transformation: explicit thunks

One can have strict structures in haskell like so:
file:Strict.hs

It's possible to recover laziness like this:
file:Lazy.hs

*** Question: What if we want to encode laziness in an imperative language?
- First introduce explicit thunks,
- Then transform them into closures!

* Concurrent programming
** Disclaimer: Concurrent programming ≠ Parallel programming

Parallel programming = expose (lack of) dependencies between parts of
the computation, so that the computer can run subtasks in parallel.

Concurrent programming = spawn independent processes, which live
independent lives (dependencies might come, but "after the fact").

In summary:
- parallelism: SPEED!
- concurrency: distribution, redundancy, ...

** "The world is concurrent!"
"
The world is concurrent
Things in the world don't share data
Things communicate with messages
Things fail                                      <- (the part we will not discuss)
" -- Joe Armstrong 
     (After his 7th victory in Tour de France)

** Process
A process is an independent thread of computation
file:Process.hs
** Channel
A medium for communication between processes.
file:Channel.hs
** Transformation: variable-managing process
file:CSPVariable.hs
** Transformation: explicit continuations
*** What is a continuation?
*** Example
A (trivial) server:
file:Server.hs
Same with explicit continuations:
file:ServerWithContinuations.hs
*** Exercise: make continuations explicit closures
** Closing
There are more models for concurrency than chanels + processes
(eg. revisions)

** TODO Paradigm shift:
* Logic programming
** Syntax
In this lecture I use the Curry syntax. 
(Similar to Haskell, plus a couple extra features)
*** Read (as needed)
   [[http://www-ps.informatik.uni-kiel.de/currywiki/documentation/tutorial][the Curry tutorial]]
** Interpreter
- Install PAKCS (recommended)
- ... or just use web interface: http://www-ps.informatik.uni-kiel.de/~mh/pakcs/curryinput_c2p.cgi
** Logic: a crash course (✪)
*** Question: what is *a logic*?

  (Sound) rules of reasoning

*** Notion: Proposition:
- A statement (can be true or false).

(A proposition that can be proved is called a theorem.)

**** Closed propositions:
- "Socrates is a man"
- "John Hughes has a tatto on the sole of his left foot"

**** Open propositions:
- "x is a man"
- "John Hughes has a tatto on x"

(The above statements _may_ be made true for some value of the (meta-)variable x)

*** Notion: Rules
(An axiom is just a rule without premiss)
**** Example: conjunction

   A        B                   <--- premisses
----------------
      A ∧ B                     <--- conclusion



     A ∧ B
----------------
       A


     A ∧ B
----------------
       B

**** Example: specialisation
      ∀x. A(x) ⇒ B(x)          A(a)
----------------------------------------
           B(a)


Famously:

   ∀x. Man(x) ⇒ Mortal(x)          Man(socrates)
 ------------------------------------------------
                   Mortal(socrates)

**** Example(⋆⋆⋆): application


   ∀x:A ⇒ B(x)          a:A
----------------------------
           B(a)


Famously:

   ∀x:Man ⇒ Mortal(x)          socrates : Man
 ------------------------------------------------
                   Mortal(socrates)

*** Proof

derive a theorem from a number of axioms, using the rules:


   axiom1   axiom4                              axiom2
 --------------------- principle           -------------- principle ...
   quux                                         foo
  ----------------------------------------------------------- principle ....
                        bar

** Transformation: Functions to relations
From "classic" math: a function is a graph:

  f : A → B

means

  f : A × B
  (x,y₁) ∈ f and (x,y₂) ∈ f   ⇒ y₁ = y₂


We can turn this around and replace functions by graphs.

| source              | target                                                        |
|---------------------+---------------------------------------------------------------|
| f : A → B          | f : A → B → Prop                                            |
| definition: f x = y | assert: f x y = y                                             |
| expression: f(x)    | expression: y (new free variable),  with the condition f(x,y) |

file:Lists.curry
** Paradigm shift:
- No longer necessary to restrict oneself to relations that describe
  functions.
- Dogma: no more functions, only relations
  + Y = f(X) is replaced by f(X,Y)
  + if X and Y are known, f(X,Y) is a testable proposition
- Provide a number of facts (axioms/rules)
- Let the computer search for an assignment of variables that make
  some statement true (proof)
- Invertible programs
  + if X known, Y is computed (f(X))
  + if Y known, X is computed (f-1(Y))  
  + Compute both directions with one piece of code
  + Very cool!!!! (parser/pretty-printer,
  compiler/decompiler...)
- Sadly, often inefficient
  + Performance of functions inverted using the above receipe can be
    terrible.

** Other example: family tree

file:Family.curry
** TODO Unification


Meaning of =:=

- Metavariable
- Unbound
- Bound

*** Trivia (⋆): what are the bindings after...
2 =:= x
[x,1] =:= [2,y]
[x,y,z] =:= [w,x,y] 

** TODO Search
*** List of successes
*** Backtracking
manual search       <-->  constraints

http://stackoverflow.com/questions/2280021/logic-variables-support-for-net


* Outlook

The following graph is an overview of all the transformations seen in
the course.

(NOTE: You should know also how to "revert" a transformation!)

#+begin_src dot :file transformations.png :cmdline -Kdot -Tpng 
digraph G {
   Imperative -> Machine [label="explicit gotos"]
   Imperative -> Machine [label="explicit stack\n(derecursification)"]
   "Object-Oriented" -> Imperative [label="explicit method pointers"]
   Functional -> Imperative [label="explicit closures\n(defunctionalization)"]
   Functional -> Imperative [label="inline higher-order fct."]
   Imperative -> Functional [label="explicit state"]
   Functional -> Functional [label="explicit thunks"]
   Imperative -> Concurrent [label="state-managing process"]
   Concurrent -> Functional [label="explicit continuations"]   
   Functional -> Logic [label="explicit result\n(embedding functions into relations)"]
   Logic -> Functional [label="explicit list of successes"]
}
#+end_src

#+results:
[[file:transformations.png]]

* Postlude: Where to go from here?
** Exam :)
- re-do the exercises
- exam will be in the same style
** Explore the paradigms you like!
** Invent your own paradigm!
- ... that suits the way you think
- ... that suits your favourite application domain
- → AFP Course
** A lot more to read ...
*** The essence of functional programming (Wadler)
 Actually a tutorial on monads.
*** A poor man's concurrency monad (Claessen)
*** The essence of list comprehensions (Wadler)
*** Andre Pang's thesis
*** Introduction to programming with shift and reset
http://okmij.org/ftp/continuations/index.html#tutorial1
*** Transforming failure into a list of successes (Wadler)
** Formal study of Syntax, Types, and Semantics
   -> Programming Languages Coures
   -> "Types and Programming Languages", Pierce
   -> Types For Proofs And Programs





#+STYLE: <link rel="stylesheet" type="text/css" href="pp.css" />
